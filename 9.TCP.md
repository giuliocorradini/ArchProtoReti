# TCP

È il primo protocollo affidabile che studiamo. È orientato alla connessione, e ragiona sul fatto che abbiamo uno
stream di dati da inviare.

Vogliamo un canale di comunicazione affidabile "virtuale". I paccheti vanno comunque inviati su un canale inaffidabile
quindi dobbiamo rilevare eventuali errori e correggerli: ritrasmettere.

## Rilevazione errori

Usiamo il checksum per garantire _l'integrità_ rispetto a errori di trasmissione. Non serve per rilevare una perdita di
un pacchetto.

Perdite, duplicati e consegne non in ordine sono problematiche che non vengono rilevate dal checksum, ma che il
protocollo gestisce.

Ho un dato da inviare, che viene suddiviso in N pacchetti.

TCP vuole garantire tutte le garanzie di affidabilità. In alcuni contesti potrebbe non offrire le performance migliori,
perché in alcuni scenari applicativi queste cose non interessano.

Quando vogliamo implementare sono "alcune" garanzia, ripartiamo da UDP e implementiamo solo certe funzioni. Ad esempio
il protocollo [QUIC](https://quicwg.org), che è basato su UDP.

Per rilevare gli errori, il destinatario conferma la ricezione di un insieme di pacchetti. La ricezione corretta di un
dato viene seguita da un _acknowledgement_. I pacchetti di _ACK_ vengono inviati ogni volta che il destinatario conferma
la corretta ricezione di un messaggio.

L'_ACK_ viene inviato in seguito al controllo del checksum, che deve essere corretto.

Per raggiungere l'affidabilità su un canale inaffidabile, devo implementare un meccanismo di conferma della ricezione.
Se il mittente non vede arrivare una conferma di corretta ricezione, deve rinviare il pacchetto.

Questo meccanismo rileva: corruzione dei pacchetti, il pacchetto viene perso. Ma di per sè non risolve i pacchetti
duplicati.

Dopo un certo timeout il mittente si accorge che qualcosa è andato storto.

La gestione dei pacchetti duplicati si risolve identificato **univocamente** ogni pacchetto all'interno di una
sequenza.

Se il destinatario vede arrivarsi due volte un pacchetto con lo stesso numero, non lo considera nello stream.

Questo tipo di acknowledgment viene detto **esplicito**, ovvero il destinatario invia la conferma di ricevuta. Ma in
alcuni protocolli potremmo avere degli acknowledgement negativi.

Nello specifico contesto in cui un pacchetto sia arrivato corrotto, il destinatario può segnalarlo al mittente con un
_negative acknowledgement_ (NACK). Una segnalazione attiva di una trasmissione errata **non avviene**, perché è rara.

## Dimensionamento timeout

A livello di Ethernet, il timeout è costante (ad esempio nel caso di una ARP request). In TCP deve essre gestito in
modo intelligente: non troppo corto per non perdere degli ACK validi in contesti ad alta latenza, e nemmeno dei timeout
troppo lunghi per reagire più in fretta, ad esempio in una rete locale.

Il dimensionamento del timeout viene fatto adattivamente, _a runtime_, osservando come la comunicazione sta avvenendo.

## Connection oriented

Anche a livello 2 possono esistere protocolli orientati alla connessione, come PPP. Un protocollo connection-oriented
ha 3 fasi (ed è composto da 3 sottoprotocolli).

Non posso inviare dati direttamente se prima non ho "aperto" la connessione, inoltre durante il normale funzionamento
devo essere in grado di "chiudere" la connessione per terminarla correttamente.

Il problema della connessione si affronta a livello logico, perché non stiamo allocando risorse su canali fisici.
L'unica cosa che introduciamo è uno stato end-to-end. Non introduciamo un carico nella rete ma tra i due partecipanti
nella comunicazione.

Mantenere uno stato = occupare della memoria.

## Segmentazione

La divisione del flusso di dati in tanti pacchetti viene detta **segmentazione**, creando tanti segmenti. TCP cerca
anche di minimizzare il numero di volte in cui è necessario segmentare un dato, anche ai livelli inferiori.

La dimensione ideale dei segmenti TCP dovrebbe essere quella del _path MTU_. La dimensione massima (in UDP) è pari
alla dimensione massima inviabile tramite un payload IP, che eventualmente viene frammentato.

$$
MTU_{UDP} = 2^{16} - 1 - |\text{header IP}|
$$

## Sequence number

Il termine sequence number è il termine tecnico con cui contiamo i pacchetti che inviamo. Ogni segmento TCP che inviamo
ha un numero univoco detto sequence number. Consideriamo questo flusso di dati come un buffer di memoria, indirizzato
dal sequence number.

## Astrazioni

L'applicazione assume di star comunicando su un canale affidabile, ma nella realtà implementativa c'è un meccanismo che
si occupa di rendere affidabile un canale inaffidabile.

## Altre funzionalità

### Trasferimento con buffer

Vengono utilizzati per rendere le comunicazioni più performanti. È possibile che il SO decida di non inviare
immediatamente i dati, ma di conservali in memoria.

Ugualmente il destinatario: prima di inviare i dati che riceve al livello 3 potrebbe decidere di tenere i dati in
memoria.

### Full-duplex

Il canale di comunicazione consente a entrambi i partecipanti alla comunicazione di comunicare contemporaneamente.
C'è una distinzione tra client e server, ma una volta instaurata la comunicazione i ruoli spariscono concettualmente.
Nello scambiarsi i dati sono alla pari.

### Controllo di flusso

Funzionalità che cerca di regolare la velocità di invio dei dati end-to-end, in base alla capcità dei partecipanti.
Si tengono in considerazione: throughput, capacità dei comunicanti e della rete (congestione).

La velocità viene sempre rimodulata. Possiamo gestire situazioni in cui le risorse della rete vengono suddivise tra più
utenti.

### Funzioni non implementate

TCP non fornisce garanzie per comunicazioni in tempo reale.

Non fornisce nemmeno garanzie di disponibilità di banda tra mittente e destinatario.

Infine TCP è un protocollo unicast, e non c'è alcuna cognizione di comunicazione multicast. Abbiamo sempre e solo due
entità che comunicano tra di loro.

### Problemi

TCP viene utilizzato su host eterogenei, con tempi di trasmissione differenti su reti differenti, possibili ritardi
nella rete e capacità computazionali molto diverse.

## Segmento

L'header di un segmento TCP è più complesso rispetto a quello di UDP. Abbiamo sempre i numeri di porta: sorgente e
destinazione, di dimensione 16 bit l'uno.

In fondo c'è un checksum, analogo del tutto a quello di UDP (protegge l'integrità dell'header e del payload).

Il _sequence number_ è a 32 bit, inoltre c'è un ulteriore campo sempre da 32 bit che conferma un certo segmento.
Acknowledgment 1 conferma la ricezione del pacchetto 1 etc.

Scelta di design: perché mettiamo un campo aggiuntivo e non riutilizziamo il sequence number? Poiché il fusso è
bidirezionale, permettiamo a ogni segmento di svolgere una doppia funzione: inviare dati e confermare quelli ricevuti
contemporaneamente.

Questa possibilità è detta _piggybacking_.

Abbiamo un campo `hlen` che indica la dimensione dell'header: abbiamo dei campi opzionali che possiamo inserire.

`code bit` è un bitfield che specifica lo scopo e contenuto del segmento: `ack`, `urg` e `psh` cerca di dire a livello
4 mittente di inviare subito il dato (flush del buffer).

Gli ultimi 3 bit sono `syn`, `fin` e `rst` che vengono utilizzati per la gestione della connessione. `syn` viene
utilizzato solo quando instauriamo la connessione. Gli altri due sono legati alla chiusura della connessione.

Ci sono due bit perché ci sono due modi per chiudere la connessione.

`window size` definisce la dimensione della finestra in ricezione (quanti byte è in grado di ricevere).

### Dati urgent

`urgent pointer` punta al termine dei dati urgenti. Siccome non è stato definito abbastanza bene nello standard, viene
raramente uitlizzato e può essere soggetto a difformità nelle implementazioni dei vari sistemi operativi.

Urgent viene usato soltanto in un sottinsieme dei dati che cerchiamo di inviare. Nelle implementazioni moderne indica
sempre un byte, ovvero si è in grado di inviare in modo urgente un singolo byte. Spesso non è implementato bene, quindi
viene accettato come urgent solo il primo byte del payload. Va verificato sperimentale in base all'implementazione.

Questi possono essere: ctrl+C, ctrl+Z etc. Di fatto sono stati pensati per contesti applicativi interattivi (come ssh).

`tcpoptions` è un campo opzionale, di lunghezza variabile. Permette anche di negoziare l'MSS (maximum segment size),
per evitare che il segmento sia frammentato dal livello IP.

Infine dobbiamo mettere un padding di zeri per allineare la lunghezza dell'header a 32 bit.

Il mittente propone inizialmente come MTU il proprio, meno l'header IP. Nell'handshake viene deciso come MSS il minimo
tra i due proposti. Se nella comunicazione inviamo un dato con un payload che crea problemi legati al path MTU,
inferiori al MSS, possiamo rinegoziarlo con la stessa modalità.

Se non viene specificato, il default MSS è 536 byte. Vicino all'MTU minimo per ogni router collegato in Internet.

## Sequence number

Fin'ora li abbiamo considerati dei contatori, ma in realtà sono degli indici di memoria. I segmenti vengono contati a
partire da un numero indipendente e pseudo-casuale. Questo valore viene chiamato _initial sequence number_.
Introduciamo un offset, la posizione effettiva è $addr - ISN$.

Sono quindi indici di una memoria virtuale. Ogni volta che inviamo dati con TCP, incrementiamo il campo sequence number
di un valore pari al numero dei dati inviati.

Ogni volta che andiamo in overflow dal sequence number, ripartiamo da zero. Abbiamo un buffer circolare di memoria.
Possiamo superire il limite di 4GiB di dati inviabili.

## Acknowledgment number

Il numero di sequenza di ACK è uguale al sequence number del primo elemento che ci aspettiamo dopo l'ultimo ricevuto.
Poniamo di aver ricevuto tutti i pacchetti da 0 a 999, allora l'ACK avrà valore 1000.

Concettualmente è la stessa cosa: indica quello che **ci aspettiamo di ricevere**.

_Piggybacking_ $\to$ "portare a cavallo sulle spalle".

Esiste una certa latenza massima che un mittente può aspettare per unire un ACK con un invio dei dati. A livello di
standard esiste una piccola finestra temporale per cui io posso inviare l'ACK, per permettermi di avere dei dati da
inviare. Dettaglio tecnico minimo.

Con questo meccanismo non dobbiamo più creare pacchetti ad hoc per l'invio di ACK.

## Instaurare una connessione

$$
%importante
$$

Prima di iniziare una comunicazione, bisogna stabilire una connessione. Il paradigma è client-server: il server si
interfaccia col SO per mettersi in ascolto su una porta. Il client si collega verso un host su una particolare porta.

In UDP abbiamo visto (sperimentalmente) che venivano inviati dei pacchetti, mentre in TCP c'è una prima fase di
instaurazione.

### Three-way handshake

Nome canonico dato all'apertura di una connessione TCP perché composta dall'inivio di 3 pacchetti.

- il client manda una connection request (pacchetto con `SYN=1` e gli invia il suo ISN nel campo seq);

- il server risponde con un `SYN` `ACK` (ovvero attiva i bit sia di `SYN` che di `ACK`) e gli invia il suo ISN nel
campo sequence (e invia l'ISN del client+1 in ack);

- il client conferma definitivamente di aprire la connessione con un `ACK` (niente `SYN`) con sequence number uguale a
$\text{client\_isn}+1$ e ack di $\text{server\_isn}+1$.

I segmenti con `SYN` = 1 non possono avere payload. Per cui l'ack in risposta sarà `client_isn` + 1 perché il payload è
zero. Cosa interessante: il client e il server inizializzano due sequence number **indipendenti**.

Al termine di questi pacchetti sia client che server sono indistinguibili. Quando il client vuole inviare dei dati
incrementa il suo sequence number e viceversa il server.

Abbiamo quindi due flussi di dati veramente indipendenti. Così client e server hanno due stati esclusivi.

### Informazioni aggiuntive

Fra le informazioni aggiuntive inserite nelle opzioni del pacchetto di SYN del client, si può inserire il proprio
`Maximum Segment Size`. Questa informazione non viene sempre inviata.

Altra informazione legata al controllo di flusso, viene inviata anche la _maximum window size_, ovvero la quantità di
memoria allocata per il buffer di ricezione. L'altra entità non manderò mai più informazioni di quante indicate nella
window size del peer.

> _Se mi invii più di tot dati, devo scartarli (quindi non inviarmeli)_

## Chiudere connessione

Ci sono due tipi di chiusure, prima vediamo la chiusura cortese (polite). Si cerca di eseguire impostando il bit `FIN`
a 1 al server.

### Polite

Funziona in questo modo:

- il client invia il pacchetto `FIN`, che avrà il suo sequence number, ma segnala anche che è l'ultimo pacchetto che
invierà. Il server risponde con un `ACK`;

- successivamente il server invia un suo pacchetto `FIN` e il client conferma con un `ACK` la ricezione del pacchetto
`FIN` del server.

Abbiamo due pacchetti che possiamo considerare come flussi indipendenti. Il server e il client considerano la
connessione chiusa effettivamente in due momenti differenti: il server appena riceve l'ACK del client, mentre il client
dopo un _timed wait_ rispetto all'invio dell'ACK finale al server.

Perché funziona così? Perché devo fare un doppio scambio di messaggi?

Quando il server riceve il FIN, il SO segnala all'applicazione questa cosa. Assumiamo che ci sia un'applicazione che
debba fare cose per gestire questa chiusura. Come minimo la deallocazione della memoria necessaria a gestire la logica
applicativa.

Se il client chiude il suo endpoint, il server può continuare a inviargli dati.

Non ha rilevanza chi decida di chiudere la connessione per primo. Il fatto che ci siano client-server è fondamentale
per l'handshake ma una volta aperta la connessione il tipo di comunicazione è fullduplex.

### Unpolite

Il server può scegliere di chiudere la connessione forzatamente inviando un singolo pacchetto `RST`, la connessione
viene considerata chiusa.

Perché esistono due modalità? La chiusura polite è affidabile, mentre quella unpolite è l'unico protocollo di TCP che
non è affidabile. Il sottoprotocollo di chiusura (con reset) non è affidabile. Non c'è alcun ACK. La chiusura è best
effort.

In alcuni contesti applicativi un'entità che vuole chiudere la connessione non ha tempo per aspettare l'ACK.

L'alternativa è che il peer si accorgerà che starà comunicando con qualcuno che non ascolta più, mantenendo le risorse
per mantenere uno stato inutile in memoria.

Reset viene usato anche per negare una connessione a un client, ad esempio se mi accorgo che a livello applicativo
il peer parla un altro protocollo.

## Affidabilità

Si impiega un meccanismo di _positive acknowledgement_. Prima di inviare il pacchetto successivo, il mittente aspetta di
ricevere un ACK di conferma per i pacchetti già inviati.

Se scaduto il timeout, il mittente non ha ricevuto un ACK per un pacchetto, lo reinvia.

Nella comunicazione può andare persa anche la conferma, allora il mittente rispedisce i dati finché non riceve la conferma.
L'acknowledgement è comunque un pacchetto IP e dal punto di vista del router non c'è differenza nella geestione dello
stesso.

## Stima del timeout

In TCP il timeout non è un valore fisso, ma è un valore da stimare in base alle condizioni della rete. Prendiamo come dato
di base il RTT (round trip time), ovvero il tempo impiegato da un pacchetto in un caso ideale per essere recapitato e
ricevere il conseguente ACK.

Come minimo il timeout deve essere maggiore del RTT. Non c'è un valore massimo per il timeout, se è troppo breve effettuo
ritrasmissioni non necessarie, mentre se il timeout è troppo largo potrei non reagire abbastanza velocemente.

Come fare a minimizzare il timeout? Il RTT non è costante, ma varia e il mio parametro dovrà tenere conto della latenza.

Iniziamente si sceglieva 2 * RTT come timeout, osservando come varia il round trip time della comunicazione adattando
il valore. Adesso si utilizzano soluzioni più sofisticate.

Facciamo una media mobile esponenziale, basata sull'idea che i valori più significativi siano gli ultimi in ordine temporale.

$$
\text{EstimatedRTT}(t) = (1-x) \cdot \text{EstimatedRTT}(t) + x \cdot \text{SampleRTT}(t)
$$

Questa è una _media pesata fatta in streaming_. Inizialmente scegliamo $x = \frac{1}{n+1}$ dove n è il numero di campioni.

Per il timeout consideriamo comunque il doppio dei valori di RTT stimata.

Per migliorare la stima possiamo introdurre anche un valore per misurare "quanto funziona bene la mia formula".

### Rete non costante

Riusciamo a introdurre un sistema per cui, in presenza di una rete che fluttua molto, permette l'adattamento a una rete
che cambia in modo repentino e costantamente?

Quanto varia il round trip time di volta in volta? Possiamo sommare alla stima la deviazione della grandezza campionaria.

Se l'RTT fluttua molto allora la deviazione sarà alta.

Moving Deviation:

$$
\text{Deviation}(t) = (1-x) \cdot \text{Deviation}(t-1) + x \cdot |SampleRTT(t) - EstimatedRTT(t)|
$$

questa formula modella quanto mi sono sbagliato in precedenza. Il contributo della deviazione è di solito associato a
un moltiplicatore 4.

La formula cerca di essere il più generale possibile. Per contesti specifici è possibile implementare soluzioni ad hoc.

## Prestazioni

Per ora abbiamo mostrato un protocollo di tipo _stop-and-wait_. Il tempo di propagazione di un pacchetto è circa RTT/2,
devo comunque fare delle assunzioni come il fatto che il tempo per trasmettere tutto il pacchetto sia trascurabile e che
il tempo per riceve l'ACK sia uguale.

Qual è il throughput posto di avere un certo RTT?

Possiamo fare una stima per un protocollo di tipo stop-and-wait, in cui il throughput effettivo è enormemente limitato
dalla **latenza** a livello end-to-end del mezzo di comunicazione.

$$
\text{Utilizzo} = \frac{t}{RTT + t}
$$

Vediamo che se RTT > t, allora la capacità del canale è utilizzat a meno del 50%. Un protocollo _stop-and-wait_ in
situazioni ad alta latenza non è adatto.

## Pipelining

Per migliorare le prestazioni invio un numero multiplo di segmenti prima di fermarsi per un acknowledgement. Dimensionata
opportunamente mi permette di migliorare le performance in contesti di alta latenza.

Con 3 pacchetti in parallelo l'utilizzo viene incrementato di un fattore 3.

Questo parametro determina la velocità di trasmissione di TCP. La velocità del mezzo fisico è importante perché governa
quanto ci mettiamo a inviare ogni segmento, la lunghezza del segmento è **calibrata sul Path MTU**.

Qui possiamo decidere quanti segmenti mettere in pipe prima di aspettare. Come si gestisce questo approccio?
Introduciamo due buffer: lato mittente e lato destinatario, con un meccanismo di sliding window.

### Lato mittente

Il mittente avrà tre variabili che devono soddisfare la seguente relazione:

$$
LSS - LAR \le SWS
$$

dove:

- $LSS$ è il numero dell'ultimo segmento inviato;

- $LAR$ ultimo ACK ricevuto;

- $SWS$ dimensione della sliding window

e determinano quale area del buffer stiamo cercando di inviare.

Tutto ciò che $\lt LSS$, ovvero l'area precedente alla sliding window rappresenta dati inviati correttamente e di cui
abbiamo ricevuto un ACK.

Tutto ciò che c'è dentro alla finestra sono segmenti che stiamo cercando di inviare e che mettiamo in pipe.

Il primo elemento della sliding window ci indica che il segmento più vecchio per non abbiamo ancora ricevuto l'ACK è 60.

### Lato destinatario

C'è un buffer simile ma che è governato in modo diverso. Poniamo che la dimesione della finestra di invio e di ricezione
siano uguali e siano costanti. Ciò che vediamo a sinistra della sliding window sono i segmenti ricevuti correttamente.

Se riceviamo un segmento all'interno della finestra di scorrimento lo possiamo accettare. Se il segmento è oltre lo
scartiamo. Uno dei problemi è legato al fatto che non si garantisce la consegna dei pacchetti IP in ordine.

Il pacchetto viene accettato solo se è all'interno della finestra. Per far avanzare la finestra di ricezione si aspetta
di ricevere dei pacchetti contigui.

Più memoria allochiamo più pacchetti fuori ordine riusciamo a gestire.

> La dimensione della finestra di invio governa quanti dati posso inviare effettivamente.

Dobbiamo dimensione il buffer mittente per non saturare il buffer destinatario. Il buffer mittente viene dimensionato
in base a quello del destinatario (controllo di flusso) e a come funziona la rete (controllo di congestione).

## Gestione acknowledgement

Nel caso di un protocollo di tipo pipeling possiamo avere due approcci: _go-back-N_ e _ritrasmissione selettiva_.
TCP adotta un approcio ibrido.

Tutto dipende da come interpretiamo gli ACK.

### Go-back-N

ACK di tipo cumulativo che conferma di aver ricevuto tutti i segmenti fino a quel valore. Questo consentirebbe di avere
in ricezione un buffer ridotto all'osso, ma significa che i pacchetti out of order vengono scartati.

### Ritrasmissione selettiva

Il mittente riceve degli ACK selettivi, ovvero si invia una conferma di aver ricevuto un certo pacchetto all'interno
della sliding window.

C'è un contesto in cui l'ACK cumulativo ci dà un vantaggio rispetto a quello selettivo. Quando ci sono pedite sugli ACK
abbiamo un vantaggio in contesto di acknowkledgement cumulativo.

> TCP accetta pacchetti fuori ordine ma non ne conferma la ricezione. Si evita la trasmissione di ACK non necessari.
Si adotta un approccio di sliding window (salvataggio dei pacchetti out-of-order) con ACK cumulativo.

Il controllo di flusso govrna il numero di segmenti in pipeline per non saturare il buffer del destinatario, mentre il
controllo di congestione osserva un fenomeno legato alla rete.

Il flusso è **end-to-end**. Entrambi cercano di influenzare lo stesso parametro: ovvero quanti segmenti mettere in pipe
e come dimensionare la sliding window del mittente.

$$
\text{EffectiveWindow} = \min(FW, CW)
$$

## Fairness

> Il concetto di non inviare più dati del necessario.

Perché non saturare sia la rete che il destinatario? Perché si cerca non sprecare inutilmente le risorse della rete e
dell'altro capo della comunicazione.

Il meccanismo di congestione è fair perché consente di suddividere equamente una banda di rete in presenza di più
connessioni TCP.

Questi protcolli sono fatti anche per suddividire la rete in modo equo in presenza di connessioni multiple concorrenti.
Un approcio differente potrebbe essere un approcio greedy. La _fairness_ non è scontata.

## Flow control

Nell'intestazione di un segmento PCB, nel campo `window size` è contenuta la dimensione di quanti dati può contenere la
sliding window. Se questo campo è uguale a 0, il mittente non deve inviare ulteriori dati.

Quand'è che il buffer si riempie? Dipende dall'applicazione: TCP è un protocollo a livello implementativo asincrono.
Finché l'applicazione non richiede i dati, quelli rimangono nel buffer.

Esempio: se un socket non consuma i dati, il buffer si riempie.

Anche se il mittente riceve una window size = 0, invia un segmento di keepalive periodicamente con l'unico obiettivo di
mandargli un'ACK con una window size aggiornata.

## Congestione

Cerca di regolare il caso in cui un numero elevato di sorgenti inviano contemporaneamente troppi dati.

In TCP si controlla la congestione con una metodologia end-to-end. Abbiamo come alterntiva il controllo della congestione
assistito: nel campo TOS del pacchetto IP c'era un campo relativo all'Explicit Congestion Notification.

Quell'informazione a livello IP è usato in alcuni AS per controllare la congestione. I router forniscono un feedback
esplicito di ciò che sta succedendo (in questo caso lo stato di congestione).

### End-to-end e slow start

Quando stabiliamo una condizione TCP non sappiamo in quale condizioni la stiamo stabilendo: l'approcio slow start è
pessimista e fa stime basse sul contesto. Dopo usiamo un approccio di tipo Additive Increase quando le cose vanno bene
mentre un approcio Multiplicative Decrease per calare drasticamente la velocità quando la rete sarà satura.

La velocità di trasmissione di TCP non vuole convergere verso una velocità, ma oscilla intorno a una certa velocità.

> Il flusso è costantemente variabile.

### Considerazioni

La rete **va bene** quando sto ricevendo correttamente l'ACK. Lo start slow configura il protocollo come uno stop and
wait del tipo più semplice possibile.

A un certo punto entro in una fase di congestion avoidance in cui calo la velocità di trasmissione. Normalmente non
c'è una sola logica che aumenta l'aumento di velocità ma a seconda del contesto vario. Questo per evitare oscillazioni
troppo forti.

## Ritrasmissione rapida

Aumento la velocità di trasmissione (numero di segmenti in pipe) finché non c'è un evento che mi costringe a calare la
velocità. Il timeout non è l'unica strategia per verificare che qualcosa è andato storto. Si usa anche il meccanismo di
ACK duplicato.

Se riceviamo un triplo ACK replicato, lo si interpreta come se fosse un NACK. La ritrasmissione viene scatenata prima
dello scadere del timeout. Concettualmente non c'è un NACK esplicito ma sfruttiamo un meccanismo per comunicarlo.

Interpretiamo il triplo ACK rispetto a un timeout. Alcuni algoritmi di congestione (Reno) dice che "se avviene un triplo
ACK duplicato bisogna dimezzare la finestra di trasmissione"; se invece si scatena un timeout bisogna ritornare alla
velocità di partenza.

L'evoluzione del protocollo di congestione è dato sia dallo studio della rete sottostante ma anche dal fatto che le
reti cambiano. Negli anni 80 le reti erano molto diverse dalle reti di oggi. Gli algoritmi si aggiornano perché la rete
cambia.

[Congestion Control](https://en.wikipedia.org/wiki/TCP_congestion_control)

TCP limita un pochino per inviare pacchetti alla massima velocità. In alcuni contesti se c'è troppo traffico UDP si
rischia di azzerare la velocità degli altri. Un uso poco attento del protocollo UDP rischia di non essere fair riseptto
a un protocollo TCP.
